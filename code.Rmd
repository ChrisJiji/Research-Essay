---
output: pdf_document
---
```{r}
# April 26
library(tidyverse)
library(effsize)
library(hypergeo)
library(BayesFactor)
library(pwr)

##################################### Effect size vs power ####################################################
r = 1e+03 # replications
effsize <- seq(0, 1, by=0.1)
pilot_n = 10
K = 2
alpha = 0.05
beta = 0.2
ps <- matrix(0, ncol=r, nrow = length(effsize))

for(i in effsize){
  for(j in 1:r){
      muvec <- c(0, i)
      # generate pilot data, calculate sample size needed
      pilot.data  <- rnorm(n = K*pilot_n, mean = rep(muvec,each=pilot_n), sd = rep(1,K*pilot_n))
      pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=pilot_n))))
      SSb <- pilot.anova[1,2]
      SSt <- pilot.anova[1,2] + pilot.anova[2,2]
      eta2 <- SSb/SSt
      temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE) 
      if ('try-error' %in% class(temp)){
        n <- 2000
      }else{
        n <- min(2000, ceiling(temp)) # round it to an integer. Round it up to ensure that you achieve the power
      }
      
      # generate population, store p-value
      study.data  <- rnorm(n = K*n, mean = rep(muvec, each=n), sd = rep(1, K*n))
      study.anova <- as.matrix(anova(aov(study.data ~ rep(as.factor(1:K), each=n))))
      ps[which(effsize==i),j] <- study.anova[1,5]
  }
}
obspower_10 <- apply(ps, 1, function(x) sum(x < .05, na.rm=TRUE)/(r-sum(is.na(x))))


pilot_n = 25
for(i in effsize){
  for(j in 1:r){
      muvec <- c(0, i)
      # generate pilot data, calculate sample size needed
      pilot.data  <- rnorm(n = K*pilot_n, mean = rep(muvec,each=pilot_n), sd = rep(1,K*pilot_n))
      pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=pilot_n))))
      SSb <- pilot.anova[1,2]
      SSt <- pilot.anova[1,2] + pilot.anova[2,2]
      eta2 <- SSb/SSt
      temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE) 
      if ('try-error' %in% class(temp)){
        n <- 2000
      }else{
        n <- min(2000, ceiling(temp)) # round it to an integer. Round it up to ensure that you achieve the power
      }
      
      # generate population, store p-value
      study.data  <- rnorm(n = K*n, mean = rep(muvec, each=n), sd = rep(1, K*n))
      study.anova <- as.matrix(anova(aov(study.data ~ rep(as.factor(1:K), each=n))))
      ps[which(effsize==i),j] <- study.anova[1,5]
  }
}
obspower_25 <- apply(ps, 1, function(x) sum(x < .05, na.rm=TRUE)/(r-sum(is.na(x))))

pilot_n = 40
for(i in effsize){
  for(j in 1:r){
      muvec <- c(0, i)
      # generate pilot data, calculate sample size needed
      pilot.data  <- rnorm(n = K*pilot_n, mean = rep(muvec,each=pilot_n), sd = rep(1,K*pilot_n))
      pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=pilot_n))))
      SSb <- pilot.anova[1,2]
      SSt <- pilot.anova[1,2] + pilot.anova[2,2]
      eta2 <- SSb/SSt
      temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE) 
      if ('try-error' %in% class(temp)){
        n <- 2000
      }else{
        n <- min(2000, ceiling(temp)) # round it to an integer. Round it up to ensure that you achieve the power
      }
      
      # generate population, store p-value
      study.data  <- rnorm(n = K*n, mean = rep(muvec, each=n), sd = rep(1, K*n))
      study.anova <- as.matrix(anova(aov(study.data ~ rep(as.factor(1:K), each=n))))
      ps[which(effsize==i),j] <- study.anova[1,5]
  }
}
obspower_40 <- apply(ps, 1, function(x) sum(x < .05, na.rm=TRUE)/(r-sum(is.na(x))))

pilot_n = 80
for(i in effsize){
  for(j in 1:r){
      muvec <- c(0, i)
      # generate pilot data, calculate sample size needed
      pilot.data  <- rnorm(n = K*pilot_n, mean = rep(muvec,each=pilot_n), sd = rep(1,K*pilot_n))
      pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=pilot_n))))
      SSb <- pilot.anova[1,2]
      SSt <- pilot.anova[1,2] + pilot.anova[2,2]
      eta2 <- SSb/SSt
      temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE) 
      if ('try-error' %in% class(temp)){
        n <- 2000
      }else{
        n <- min(2000, ceiling(temp)) # round it to an integer. Round it up to ensure that you achieve the power
      }
      
      # generate population, store p-value
      study.data  <- rnorm(n = K*n, mean = rep(muvec, each=n), sd = rep(1, K*n))
      study.anova <- as.matrix(anova(aov(study.data ~ rep(as.factor(1:K), each=n))))
      ps[which(effsize==i),j] <- study.anova[1,5]
  }
}
obspower_80 <- apply(ps, 1, function(x) sum(x < .05, na.rm=TRUE)/(r-sum(is.na(x))))

plot(effsize, obspower_80, main="Effect size vs Observed Power", col=rainbow(4)[4], type="l", ylim = c(0, 1), 
     xlab = "Effect Size", ylab = "Observed Power")
points(effsize, obspower_40, col=rainbow(4)[3], type="l")
points(effsize, obspower_25, col=rainbow(4)[2], type="l")
points(effsize, obspower_10, col=rainbow(4)[1], type="l")
legend("bottomright", legend=c("10", "25", "40", "80"), col=rainbow(4), lty=1, title="Sample size")



##################################### Effect size vs sample size needed ####################################################
r = 1e+03 # replications
effsize <- seq(0, 1, by=0.1)
K = 2
alpha = 0.05
beta = 0.2
#theoretical sample size needed
samp_size_needed <- sapply(2:length(effsize), function(x){
  pwr.t.test(d = effsize[x], sig.level = alpha, power = 1-beta)$n
})

pilot_n = 10
samps_10 <- matrix(0, ncol=r, nrow = length(effsize))
for(i in effsize){
  for(j in 1:r){
      muvec <- c(0, i)
      # generate pilot data, calculate sample size needed
      pilot.data  <- rnorm(n = K*pilot_n, mean = rep(muvec,each=pilot_n), sd = rep(1,K*pilot_n))
      pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=pilot_n))))
      SSb <- pilot.anova[1,2]
      SSt <- pilot.anova[1,2] + pilot.anova[2,2]
      eta2 <- SSb/SSt
      temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE) 
      if ('try-error' %in% class(temp)){
        n <- NA
      }else{
        n <- ceiling(temp) # round it to an integer. Round it up to ensure that you achieve the power
      }
      samps_10[which(effsize==i),j] <- n
  }
}
samps_1010 <- apply(samps_10, 1, quantile, probs=0.10)
samps_1020 <- apply(samps_10, 1, quantile, probs=0.20)
samps_10med <- apply(samps_10, 1, quantile, probs=0.5)
samps_1080 <- apply(samps_10, 1, quantile, probs=0.80)
samps_1090 <- apply(samps_10, 1, quantile, probs=0.90)
plot(effsize, samps_10med, main="Effect size vs Sample size needed (n = 10)", col="red", type="l", 
     ylim = c(0, max(samp_size_needed, min(samps_1090, 2000))), xlab = "Effect Size", ylab = "Sample size needed")
points(effsize[2:11], samp_size_needed, col="black", type="l")
polygon(c(effsize, rev(effsize)), c(samps_1020, rev(samps_1080)), col = rgb(1,0,0, 0.25), border=NA)
polygon(c(effsize, rev(effsize)), c(samps_1010, rev(samps_1090)), col = rgb(1,0,0, 0.25), border=NA)
legend("topright", legend=c("Median calculated sample size", "Theoretical sample size", "(20%, 80%) quantiles", "(10%, 90%) quantiles"), col=c("red", "black", rgb(1,0,0,0.5), rgb(1,0,0,0.25)), lty=c(1,1,NA,NA), pch = c(NA, NA, 15, 15))



pilot_n = 25
samps_25 <- matrix(0, ncol=r, nrow = length(effsize))
for(i in effsize){
  for(j in 1:r){
      muvec <- c(0, i)
      # generate pilot data, calculate sample size needed
      pilot.data  <- rnorm(n = K*pilot_n, mean = rep(muvec,each=pilot_n), sd = rep(1,K*pilot_n))
      pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=pilot_n))))
      SSb <- pilot.anova[1,2]
      SSt <- pilot.anova[1,2] + pilot.anova[2,2]
      eta2 <- SSb/SSt
      temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE) 
      if ('try-error' %in% class(temp)){
        n <- NA
      }else{
        n <- ceiling(temp) # round it to an integer. Round it up to ensure that you achieve the power
      }
      samps_25[which(effsize==i),j] <- n
  }
}
samps_2510 <- apply(samps_25, 1, quantile, probs=0.10)
samps_2520 <- apply(samps_25, 1, quantile, probs=0.20)
samps_25med <- apply(samps_25, 1, quantile, probs=0.5)
samps_2580 <- apply(samps_25, 1, quantile, probs=0.80)
samps_2590 <- apply(samps_25, 1, quantile, probs=0.90)
plot(effsize, samps_25med, main="Effect size vs Sample size needed (n = 25)", col="red", type="l", 
     ylim = c(0, max(samp_size_needed, min(samps_2590, 2000))), xlab = "Effect Size", ylab = "Sample size needed")
points(effsize[2:11], samp_size_needed, col="black", type="l")
polygon(c(effsize, rev(effsize)), c(samps_2520, rev(samps_2580)), col = rgb(1,0,0, 0.25), border=NA)
polygon(c(effsize, rev(effsize)), c(samps_2510, rev(samps_2590)), col = rgb(1,0,0, 0.25), border=NA)
legend("topright", legend=c("Median calculated sample size", "Theoretical sample size", "(20%, 80%) quantiles", "(10%, 90%) quantiles"), col=c("red", "black", rgb(1,0,0,0.5), rgb(1,0,0,0.25)), lty=c(1,1,NA,NA), pch = c(NA, NA, 15, 15))


########################################## COS ##################################################################
findPOS <- function(n, estimates, ES, width) {
	COS <- ES + c(-1, 1) * width
	breaks <- which(estimates < COS[1] | estimates > COS[2])
	if (is.infinite(max(breaks))) {
		n.stable <- min(n)	# no break: POS = minimal sample size
	} else {
			BREAK <- max(breaks)	# get first break (seen from the tail)
		if (is.na(BREAK)) {
			n.stable <- min(n)	# no break? POS = minimal sample size
		} else {
			n.stable <- n[BREAK]
		}
	}
	return(data.frame(POS=n.stable, w=width))
}

ES = 0.1379 # large effect size
width = ES * 0.5
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)
B <- 1000 # number of bootstrap
n <- 500 # sample size per group
samps <- 20:n

pilot.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= 2*n), 
                          "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))
POS <- sapply(1:B, function(x) {
  #draw the bootstrap sample
  bootstrap <- sample_n(pilot.data, 2 * n, replace=TRUE)
  estimates <- sapply(samps, function(x) {
    pilot.anova <- as.matrix(anova(aov(effect ~ ., data=bootstrap[1:x,])))
    SSb <- pilot.anova[1,2]
    SSt <- pilot.anova[1,2] + pilot.anova[2,2]
    SSb/SSt #Estimate of effect size (eta2)
  })
  findPOS(samps, estimates, ES, width)$POS
})
hist(POS, main = "Points of Stability (large effect size)")
abline(v = pwr.t.test(d = 0.8, sig.level = alpha, power = 1-beta)$n)


ES = 0.0588 # medium effect size
width = ES * 0.5
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)
B <- 1000 # number of bootstrap
n <- 500 # sample size per group
samps <- 20:n

pilot.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= 2*n), 
                          "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))
POS <- sapply(1:B, function(x) {
  #draw the bootstrap sample
  bootstrap <- sample_n(pilot.data, 2 * n, replace=TRUE)
  estimates <- sapply(samps, function(x) {
    pilot.anova <- as.matrix(anova(aov(effect ~ ., data=bootstrap[1:x,])))
    SSb <- pilot.anova[1,2]
    SSt <- pilot.anova[1,2] + pilot.anova[2,2]
    SSb/SSt #Estimate of effect size (eta2)
  })
  findPOS(samps, estimates, ES, width)$POS
})
hist(POS, main = "Points of Stability (medium effect size)", breaks=seq(0,500, by=10))
abline(v = pwr.t.test(d = 0.5, sig.level = alpha, power = 1-beta)$n)


ES <- 0.1379 # effect size
f2 <- ES/(1-ES)
a = sqrt(f2)
muvec = c(-a, a)
K = 2 # number of groups
alpha = 0.05 # sig level
beta = 0.2 # power
R <- 1000 # replications
n = 10 # sample size
effs_10 <- rep(0, R) # effect sizes
ns_10 <- rep(0, R)# sample sizes
for(r in 1:R){
  pilot.data  <- rnorm(n = K*n, mean = rep(muvec,each=n), sd = rep(1,K*n))
  pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=n))))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  eta2 <- SSb/SSt
  effs_10[r] <- eta2
  temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE)
  if ('try-error' %in% class(temp)) ns_10[r] <- NA
  else ns_10[r] <- ceiling(temp)
}



n = 25
effs_25 <- rep(0, R) # effect sizes
ns_25 <- rep(0, R)# sample sizes
for(r in 1:R){
  pilot.data  <- rnorm(n = K*n, mean = rep(muvec,each=n), sd = rep(1,K*n))
  pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=n))))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  eta2 <- SSb/SSt
  effs_25[r] <- eta2
  temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE)
  if ('try-error' %in% class(temp)) ns_10[r] <- NA
  else ns_25[r] <- ceiling(temp)
}

n = 50
effs_50 <- rep(0, R) # effect sizes
ns_50 <- rep(0, R)# sample sizes
for(r in 1:R){
  pilot.data  <- rnorm(n = K*n, mean = rep(muvec,each=n), sd = rep(1,K*n))
  pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=n))))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  eta2 <- SSb/SSt
  effs_50[r] <- eta2
  temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE)
  if ('try-error' %in% class(temp)) ns_10[r] <- NA
  else ns_50[r] <- ceiling(temp)
}

effs <- data.frame(cbind(effs_10, effs_25, effs_50))
effs %>% pivot_longer(1:3)  %>% 
  ggplot(aes(x = name, y = value, fill = name)) + geom_violin() + xlab("Sample Size") + 
  ylab("Effect Size Estimate") + ggtitle("Effect Size Estimate vs Sample Size") + scale_x_discrete(labels = c("10", "25", "50")) + 
  geom_point(aes(x = 1, y = ES)) + geom_point(aes(x = 2, y = ES)) + geom_point(aes(x = 3, y = ES)) + 
  theme(legend.position = "none")

percent_in <- 0.2
effs %>% pivot_longer(1:3) %>% mutate(propin = value > (1-percent_in) * ES & value < (1+percent_in) * ES) %>% group_by(name) %>% summarize(mean = mean(propin)) %>% ggplot(aes(x=name, y=mean)) + geom_bar(stat="identity") + scale_x_discrete(labels = c("10", "25", "50")) + ylab(paste("Proportion within ", 100*percent_in, "% of true value", sep="")) + ggtitle("Proportion of data within 20% of true value (large effect size)")

percent_in <- 0.4
effs %>% pivot_longer(1:3) %>% mutate(propin = value > (1-percent_in) * ES & value < (1+percent_in) * ES) %>% group_by(name) %>% summarize(mean = mean(propin)) %>% ggplot(aes(x=name, y=mean)) + geom_bar(stat="identity") + scale_x_discrete(labels = c("10", "25", "50")) + ylab(paste("Proportion within ", 100*percent_in, "% of true value", sep=""))+ ggtitle("Proportion of data within 40% of true value (large effect size)")

```

```{r}
# April 13
library(tidyverse)
library(effsize)
library(hypergeo)
library(BayesFactor)
r = 1e+03 # replications
effsize <- seq(0, 1, by=0.1)
samples <- c(10, 25, 50)

##################################### Effect size vs contained in CI ####################################################
N = 800
CI_effsize_5 <- rep(0, 11) # vector to store mean CI coverage
n = N*0.05 # sample size
for(i in effsize){
  # create population to draw from
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  contained_in_CI <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n) #sample from population
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s) #calculate Cohen's d
    ifelse((i > d$conf.int[1]) & (i < d$conf.int[2]), 1, 0)
  })
  CI_effsize_5[i*10+1] <- mean(contained_in_CI)
}

CI_width_10 <- rep(0, 11)
n = N*0.1
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(d$conf.int[2] - d$conf.int[1])
  })
  CI_width_10[i*10 + 1] <- mean(widths)
}

plot(effsize, CI_effsize_10, main="Effect size vs CI coverage", col="blue", type="l", ylim = c(0.8, 1), 
     xlab = "Effect Size", ylab = "CI Coverage")
points(effsize, CI_effsize_5, col="red", type="l")
legend("bottomright", legend=c("5%", "10%"), col=c("red", "blue"), lty=1, title="Sample size")


SEM_effsize_5 <- rep(0, 11)
n = N*0.05 # sample size
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  contained_in_SEM <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    ifelse((i > d$estimate - d$sd/sqrt(n)) & 
           (i < d$estimate + d$sd/sqrt(n)), 1, 0)
  })
  SEM_effsize_5[i*10+1] <- mean(contained_in_SEM)
}

n = N*0.1 # sample size
SEM_effsize_10 <- rep(0, 11)
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  contained_in_SEM <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    ifelse((i > d$estimate - d$sd/sqrt(n)) & 
           (i < d$estimate + d$sd/sqrt(n)), 1, 0)
  })
  SEM_effsize_10[i*10+1] <- mean(contained_in_SEM)
}
plot(effsize, SEM_effsize_10, main="Effect size vs SEM coverage", col="blue", type="l", ylim = c(0.4, 0.6), 
     xlab = "Effect Size", ylab = "CI Coverage")
points(effsize, SEM_effsize_5, col="red", type="l")
legend("bottomright", legend=c("5%", "10%"), col=c("red", "blue"), lty=1, title="Sample size")

CI_width <- rep(0, 20)
sample_sizes <- seq(0.05, 1, by=0.05)
for(i in sample_sizes){
  treatment = rnorm(N, mean = 0.2)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, i*N)
    control_s = sample(control, i*N)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(d$conf.int[2] - d$conf.int[1])
  })
  CI_width[i*20] <- mean(widths)
}
temp <- data.frame("n" = sample_sizes, "width" = CI_width)
temp %>% ggplot(aes(x = n, y = width)) + geom_line() + ggtitle("CI Width vs. Sample Size") + 
  xlab("Sample Size (% of population)") + ylab("Width of CI")

############################################## Effect size estimates and sample size estimates ##########################
ES <- 0.0099 # effect size
f2 <- ES/(1-ES)
a = sqrt(f2)
muvec = c(-a, a)
K = 2 # number of groups
alpha = 0.05 # sig level
beta = 0.2 # power
R <- 1000 # replications
n = 10 # sample size
effs_10 <- rep(0, R) # effect sizes
ns_10 <- rep(0, R)# sample sizes
for(r in 1:R){
  pilot.data  <- rnorm(n = K*n, mean = rep(muvec,each=n), sd = rep(1,K*n))
  pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=n))))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  eta2 <- SSb/SSt
  effs_10[r] <- eta2
  temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE)
  if ('try-error' %in% class(temp)) ns_10[r] <- NA
  else ns_10[r] <- ceiling(temp)
}



n = 25
effs_25 <- rep(0, R) # effect sizes
ns_25 <- rep(0, R)# sample sizes
for(r in 1:R){
  pilot.data  <- rnorm(n = K*n, mean = rep(muvec,each=n), sd = rep(1,K*n))
  pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=n))))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  eta2 <- SSb/SSt
  effs_25[r] <- eta2
  temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE)
  if ('try-error' %in% class(temp)) ns_10[r] <- NA
  else ns_25[r] <- ceiling(temp)
}

n = 50
effs_50 <- rep(0, R) # effect sizes
ns_50 <- rep(0, R)# sample sizes
for(r in 1:R){
  pilot.data  <- rnorm(n = K*n, mean = rep(muvec,each=n), sd = rep(1,K*n))
  pilot.anova <- as.matrix(anova(aov(pilot.data ~ rep(as.factor(1:K),each=n))))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  eta2 <- SSb/SSt
  effs_50[r] <- eta2
  temp <- try(pwr.t.test(d = 2 * sqrt(eta2/(1-eta2)), sig.level = alpha, power = 1-beta)$n, silent = TRUE)
  if ('try-error' %in% class(temp)) ns_10[r] <- NA
  else ns_50[r] <- ceiling(temp)
}

effs <- data.frame(cbind(effs_10, effs_25, effs_50))
effs %>% pivot_longer(1:3) %>% ggplot(aes(x = name, y = value, fill = name)) + geom_violin() + xlab("Sample Size") + 
  ylab("Effect Size Estimate") + ggtitle("Effect Size Estimate vs Sample Size") + scale_x_discrete(labels = c("10", "25", "50")) + 
  geom_point(aes(x = 1, y = 0.0099)) + geom_point(aes(x = 2, y = 0.0099)) + geom_point(aes(x = 3, y = 0.0099)) + 
  theme(legend.position = "none")

ns <- data.frame(cbind(ns_10, ns_25, ns_50))
n_needed <- pwr.t.test(d=0.2, sig.level=0.05, power=0.8)$n
ns %>% pivot_longer(1:3) %>% filter(value <= 2000) %>% 
  ggplot(aes(x = name, y = value, fill = name)) + geom_violin() + xlab("Sample Size") + 
  ylab("Effect Size Estimate") + ggtitle("Sample Size Estimate vs Sample Size") + scale_x_discrete(labels = c("10", "25", "50")) + 
  geom_point(aes(x = 1, y = n_needed)) + geom_point(aes(x = 2, y = n_needed)) + geom_point(aes(x = 3, y = n_needed)) + 
  theme(legend.position = "none")
################################################## COS ########################################### 
findPOS <- function(n, estimates, ES, width) {
	COS <- ES + c(-1, 1) * width
	breaks <- which(estimates < COS[1] | estimates > COS[2])
	if (is.infinite(max(breaks))) {
		n.stable <- min(n)	# no break: POS = minimal sample size
	} else {
			BREAK <- max(breaks)	# get first break (seen from the tail)
		if (is.na(BREAK)) {
			n.stable <- min(n)	# no break? POS = minimal sample size
		} else {
			n.stable <- n[BREAK]
		}
	}
	return(data.frame(POS=n.stable, w=width))
}

ES = 0.0099 # small effect size
width = c(0, 0.0198)
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)
B <- 1000 # number of bootstrap

n <- 500 # sample size per group
samps <- 10:n

pilot.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= 2*n), 
                          "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))

# for a single sample
estimates <- sapply(3:n, function(x) {
  pilot.anova <- as.matrix(anova(aov(effect ~ ., data=pilot.data[1:x,])))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  SSb/SSt #Estimate of effect size (eta2)
})
plot(estimates, type="l", ylim=c(0, max(ES, max(estimates))), xlab="Sample Size", ylab=bquote(eta^2), lwd=3)
abline(h = ES)
abline(h = width, lty = 2)

for(i in 1:B) {
  #draw the bootstrap sample
  bootstrap <- sample_n(pilot.data, 2 * n, replace=TRUE)
  estimates_bootstrap <- sapply(samps, function(x) {
    pilot.anova <- as.matrix(anova(aov(effect ~ ., data=bootstrap[1:x,])))
    SSb <- pilot.anova[1,2]
    SSt <- pilot.anova[1,2] + pilot.anova[2,2]
    SSb/SSt #Estimate of effect size (eta2)
  })
  points(10:n, estimates_bootstrap, type="l", col=rgb(1,1,1,0.5))
}


############################################## v statistic ##########################
vstat = function(n,p,Rsq)
{
	"This function takes total sample size, n, the number of parameters, p, and the population
	value of the coefficient of multiple determination, R^2 (Rsq), and outputs the value of 
	the v-measure (Davis-Stober & Dana, 2013)."
	
	if (Rsq<=0) {Rsq = .0001}
  if (Rsq >= 0.234) {Rsq = 0.234}
  r = ((p-1)*(1-Rsq))/((n-p)*Rsq)
  g = min(r,1)
	if (g<.5001 && g>.4999) {g = .5001}
  z = (g - sqrt(g-g^2))/(2*g - 1)
  alpha = acos((1-z)/sqrt(1-2*z*(1-z)))
  v = Re((((2*cos(alpha)*gamma((p+2)/2))/(sqrt(pi)*gamma((p+1)/2)))*(hypergeo(.5,(1-p)/2, 3/2, cos(alpha)^2) - sin(alpha)^(p-1))))
  return(v)
}

find_n <- function(p, v, Rsq) { #finds the n required for a given v statistic v
  ns <- sapply(10:500, function(n) {
    if(vstat(n, p, Rsq) >= v) n
    else NA
  })
  return(ns[which.min(ns)])
}

n <- 10 # sample size per group
ES = 0.0099 # Large effect size
R = 1000
f2 <- ES/(1-ES)
f <- sqrt(3*f2/2)
muvec <- c(-f, 0, f)
small <- sapply(1:R, function(x){
  pilot.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= 3*n), 
                          "effect" = rnorm(n = 3*n, mean = rep(muvec, length.out=3*n), sd = 1))
  pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  estimate <- SSb/SSt
  
  fit <- lm(effect ~., data=pilot.data)
  r2 <- summary(fit)$r.squared
  n <- find_n(2, 0.8, r2)
  
  c(estimate,n)
})
effs_10 <- sapply(1:R, function(x){
  small[[x]][1]
})
ns_10 <- sapply(1:R, function(x){
  small[[x]][2]
})


effs <- data.frame(cbind(effs_10, effs_25, effs_50))
effs %>% pivot_longer(1:3) %>% ggplot(aes(x = name, y = value, fill = name)) + geom_violin() + xlab("Sample Size") + 
  ylab("Effect Size Estimate") + ggtitle("Effect Size Estimate vs Sample Size") + scale_x_discrete(labels = c("10", "25", "50")) + 
  geom_point(aes(x = 1, y = 0.0099)) + geom_point(aes(x = 2, y = 0.0099)) + geom_point(aes(x = 3, y = 0.0099)) + 
  theme(legend.position = "none")

ns <- data.frame(cbind(ns_10, ns_25, ns_50))
n_needed <- pwr.t.test(d=0.2, sig.level=0.05, power=0.8)$n
ns %>% pivot_longer(1:3) %>% filter(value <= 2000) %>% 
  ggplot(aes(x = name, y = value, fill = name)) + geom_violin() + xlab("Sample Size") + 
  ylab("Effect Size Estimate") + ggtitle("Sample Size Estimate vs Sample Size") + scale_x_discrete(labels = c("10", "25", "50")) + 
  geom_point(aes(x = 1, y = n_needed)) + geom_point(aes(x = 2, y = n_needed)) + geom_point(aes(x = 3, y = n_needed)) + 
  theme(legend.position = "none")



##################################### Bayesian stuff #################################################
get_bf <- function(n) {
  pilot.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= 2*n), 
                            "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))
    ## 2. Do the Bayesian t-test
    test <- ttestBF(formula = effect ~ condition, data = pilot.data)
    ## 3. Get the Bayes Factor
    ## We have to change the format to data.frame to extract the Bayes Factor
    bf <- test %>% data.frame() %>% select(bf) %>% as.numeric()
    ## 4. return it to the user
    return(bf)
}

ES <- 0.0588 # Effect size
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)

monte <- tibble(n = rep(seq(from = 10, to = 600, by = 10), each = 1000)) %>% # creates data frame of 1000 reps of 10:200
    mutate(bf = map_dbl(n, get_bf)) # applies get bf to each n 
power <- monte %>%
    group_by(n) %>%
    summarise(power = 1 - (sum(between(bf, 1/3, 3)) / 1000))
ggplot(power, aes(x = n, y = power)) +
    # Make a line graph
    geom_line(linetype = 2) +
    # Add points with different colours for our criterion
    # Increase the size of those points for better visibility
    geom_point(size = 2) +
    # Put a vertical line at 50 on the x axis
    geom_hline(aes(yintercept = 0.8)) + 
    geom_vline(aes(xintercept = ceiling(pwr.t.test(d=muvec[2]-muvec[1], sig.level =0.05, power=0.8)$n))) + 
    # Rename axis labels
    xlab("sample size") + ggtitle("Medium effect size") + 
    ylab("power") +
    # nice theme
    theme_classic()
```



```{r}
library(pwr)
# theoretical sample size needed for d = 0.2 (small effect)
pwr.t.test(d=0.2, sig.level=0.05, power=0.8)

# ------------------------- https://www.andywills.info/rminr/power-bayesian.html ---------------------
library(BayesFactor)
library(tidyverse)
# small ----------------------------------------------------------------------------------------------
ES <- 0.0099 # Effect size
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)

## get Bayesian Factor from sample size 
get_bf <- function(n) {
  pilot.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= 2*n), 
                            "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))
    ## 2. Do the Bayesian t-test
    test <- ttestBF(formula = effect ~ condition, data = pilot.data)
    ## 3. Get the Bayes Factor
    ## We have to change the format to data.frame to extract the Bayes Factor
    bf <- test %>% data.frame() %>% select(bf) %>% as.numeric()
    ## 4. return it to the user
    return(bf)
}
monte <- tibble(n = rep(seq(from = 10, to = 600, by = 10), each = 1000)) %>% # creates data frame of 1000 reps of 10:200
    mutate(bf = map_dbl(n, get_bf)) # applies get bf to each n 
power <- monte %>%
    group_by(n) %>%
    summarise(power = 1 - (sum(between(bf, 1/3, 3)) / 1000))
ggplot(power, aes(x = n, y = power)) +
    # Make a line graph
    geom_line(linetype = 2) +
    # Add points with different colours for our criterion
    # Increase the size of those points for better visibility
    geom_point(size = 2) +
    # Put a vertical line at 50 on the x axis
    geom_hline(aes(yintercept = 0.8)) + 
    geom_vline(aes(xintercept = ceiling(pwr.t.test(d=muvec[2]-muvec[1], sig.level =0.05, power=0.8)$n))) + 
    # Rename axis labels
    xlab("sample size") + ggtitle("Small effect size")
    ylab("power") +
    # nice theme
    theme_classic()

# medium ----------------------------------------------------------------------------------------------
ES <- 0.0588 # Effect size
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)

monte <- tibble(n = rep(seq(from = 10, to = 600, by = 10), each = 1000)) %>% # creates data frame of 1000 reps of 10:200
    mutate(bf = map_dbl(n, get_bf)) # applies get bf to each n 
power <- monte %>%
    group_by(n) %>%
    summarise(power = 1 - (sum(between(bf, 1/3, 3)) / 1000))
ggplot(power, aes(x = n, y = power)) +
    # Make a line graph
    geom_line(linetype = 2) +
    # Add points with different colours for our criterion
    # Increase the size of those points for better visibility
    geom_point(size = 2) +
    # Put a vertical line at 50 on the x axis
    geom_hline(aes(yintercept = 0.8)) + 
    geom_vline(aes(xintercept = ceiling(pwr.t.test(d=muvec[2]-muvec[1], sig.level =0.05, power=0.8)$n))) + 
    # Rename axis labels
    xlab("sample size") + ggtitle("Medium effect size") + 
    ylab("power") +
    # nice theme
    theme_classic()


# ------------ Biesanz ------------------ # 
setwd("F:/Chris Ji PC/Documents/Research/Research Paper")
source("BiesanzSchrager.R")
M = 100 # Replications
ES <- 0.0099 # Effect size
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)

get_n_study <- function(n_pilot){
  n <- n_pilot
  pilot.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= 2*n), 
                          "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))
  pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  (eta2 <- SSb/SSt) #Estimate of effect size (eta2)
  d = 2 * sqrt(eta2/(1-eta2))
  sd <- sqrt(((n/2+n/2)/((n/2)*(n/2))+(d*d)/(2*(n/2+n/2-2)))*((n/2+n/2)/(n/2+n/2-2))) 
  posHB <- HB(d, sd, pilot.anova[2,1], 1000, 5, 10000)
  return(PPOWER(effect=d, n1=n/2, n2=n/2, DesiredPower=.80, lowern=5, uppern=1000, alpha=.05, type="d", posterior= posHB))
}

monte <- tibble(n = rep(seq(from = 10, to = 600, by = 10), each = 100)) %>% # creates data frame of 1000 reps of 10:200
    mutate(n = map_dbl(n, get_n_study)) 

```


```{r}
# March 27 
# ------------------------------------------------------------------------------  v-statistic ---------------------------------------------------------
library(hypergeo)

vstat = function(n,p,Rsq)
{
	"This function takes total sample size, n, the number of parameters, p, and the population
	value of the coefficient of multiple determination, R^2 (Rsq), and outputs the value of 
	the v-measure (Davis-Stober & Dana, 2013)."
	
	if (Rsq<=0) {Rsq = .0001}
  if (Rsq >= 0.234) {Rsq = 0.234}
  r = ((p-1)*(1-Rsq))/((n-p)*Rsq)
  g = min(r,1)
	if (g<.5001 && g>.4999) {g = .5001}
  z = (g - sqrt(g-g^2))/(2*g - 1)
  alpha = acos((1-z)/sqrt(1-2*z*(1-z)))
  v = Re((((2*cos(alpha)*gamma((p+2)/2))/(sqrt(pi)*gamma((p+1)/2)))*(hypergeo(.5,(1-p)/2, 3/2, cos(alpha)^2) - sin(alpha)^(p-1))))
  return(v)
}

find_n <- function(p, v, Rsq) { #finds the n required for a given v statistic v
  ns <- sapply(10:500, function(n) {
    if(vstat(n, p, Rsq) >= v) n
    else NA
  })
  return(ns[which.min(ns)])
}


M <- 1000 # replications
n <- 10 # sample size per group
ES = 0.1379 # Large effect size
v <- 0.5 # v-statistic required 

f2 <- ES/(1-ES)
f <- sqrt(3*f2/2)
muvec <- c(-f, 0, f)

large <- sapply(1:M, function(x){
  pilot.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= 3*n), 
                          "effect" = rnorm(n = 3*n, mean = rep(muvec, length.out=3*n), sd = 1))
  #pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
  #SSb <- pilot.anova[1,2]
  #SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  #estimate <- SSb/SSt
  
  fit <- lm(effect ~., data=pilot.data)
  r2 <- summary(fit)$r.squared
  n <- find_n(2, v, r2)
  estimate <- r2/(1-r2)
  
  if (x %% 100 == 0) print(x)
  c(estimate,n)
})
large_eff <- sapply(1:M, function(x){
  large[[x]][1]
})
large_n <- sapply(1:M, function(x){
  large[[x]][2]
})
large_p <- sapply(1:M, function(x){
  n = large_n[x]
  if(is.na(n)){ return(NA) }
  study.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= n), 
                          "effect" = rnorm(n = n, mean = rep(muvec, length.out=n), sd = 1))
  study.anova <- as.matrix(anova(aov(effect~.,data=study.data)))
  study.anova[1,5]
})
sum(large_p<0.05, na.rm=TRUE)/(M-sum(is.na(large_p)))

# ------------------------------------------------------------------------------ Bayesian ---------------------------------------------------------
## One sample
setwd("F:/Chris Ji PC/Documents/Research/Research Paper")
source("BiesanzSchrager.R")
n <- 10 # sample size per group
ES = 0.1379 # Large effect size
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)
pilot.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= 2*n), 
                          "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))
pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
SSb <- pilot.anova[1,2]
SSt <- pilot.anova[1,2] + pilot.anova[2,2]
(eta2 <- SSb/SSt) #Estimate of effect size (eta2)
d = 2 * sqrt(eta2/(1-eta2))
sd <- sqrt(((n/2+n/2)/((n/2)*(n/2))+(d*d)/(2*(n/2+n/2-2)))*((n/2+n/2)/(n/2+n/2-2))) 

posHB <- HB(d, sd, pilot.anova[2,1], 10000, 5, 100000)
PPOWER(effect=d, n1=n/2, n2=n/2, DesiredPower=.80, lowern=25, uppern=400, alpha=.05, type="d", posterior= posHB)

## Simulation
setwd("F:/Chris Ji PC/Documents/Research/Research Paper")
source("BiesanzSchrager.R")
M = 10 # Replications
n <- 25 # sample size per group
ES <- 0.1379 # Effect size
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)
ns <- sapply(1:M, function(x){
  pilot.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= 2*n), 
                          "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))
  pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  (eta2 <- SSb/SSt) #Estimate of effect size (eta2)
  d = 2 * sqrt(eta2/(1-eta2))
  sd <- sqrt(((n/2+n/2)/((n/2)*(n/2))+(d*d)/(2*(n/2+n/2-2)))*((n/2+n/2)/(n/2+n/2-2))) 
  posHB <- HB(d, sd, pilot.anova[2,1], 10000, 5, 100000)
  PPOWER(effect=d, n1=n/2, n2=n/2, DesiredPower=.80, lowern=25, uppern=400, alpha=.05, type="d", posterior= posHB)
})

ns <- c(277, 142, 294, 293, 256, 221, 296, 288, 296, 283)
study_p <- sapply(1:M, function(x){
  n = ns[x]
  if(is.na(n)){ return(NA) }
  study.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= n), 
                          "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))
  study.anova <- as.matrix(anova(aov(effect~.,data=study.data)))
  study.anova[1,5]
})
sum(study_p<0.05, na.rm=TRUE)/(M-sum(is.na(study_p)))

```


```{r}
library(dplyr)
# March 13
# ------------------------------------------------------------------ COS ------------------------------------------------------------------
#helper to find PoS
# @param n Vector of sample sizes
# @param R Vector of correlations
# @param rho The true correlation
# @param w Half-width of corridor of stability
# @param inarow How many breaks must take place in a row to qualify for a "real" break?
findPOS <- function(n, estimates, ES, width) {
	COS <- ES + c(-1, 1) * width
	breaks <- which(estimates < COS[1] | estimates > COS[2])
	if (is.infinite(max(breaks))) {
		n.stable <- min(n)	# no break: POS = minimal sample size
	} else {
			BREAK <- max(breaks)	# get first break (seen from the tail)
		if (is.na(BREAK)) {
			n.stable <- min(n)	# no break? POS = minimal sample size
		} else {
			n.stable <- n[BREAK]
		}
	}
	return(data.frame(POS=n.stable, w=width))
}

ES = 0.1379 # Large effect size
width = (0.1379 - 0.0588) / 2 # arbitrarily defining width to be half way towards medium effect size
f <- sqrt(ES/(1-ES)) # Cohen's f
muvec <- c(-f, f)
B <- 1000 # number of bootstrap

n <- 1000 # sample size per group
samps <- 10:n

pilot.data  <- data.frame("condition" = rep(as.factor(1:2), length.out= 2*n), 
                          "effect" = rnorm(n = 2*n, mean = rep(muvec, length.out=2*n), sd = 1))

POS <- sapply(1:B, function(x) {
  #draw the bootstrap sample
  bootstrap <- sample_n(pilot.data, 2 * n, replace=TRUE)
  estimates <- sapply(samps, function(x) {
    pilot.anova <- as.matrix(anova(aov(effect ~ ., data=bootstrap[1:x,])))
    SSb <- pilot.anova[1,2]
    SSt <- pilot.anova[1,2] + pilot.anova[2,2]
    SSb/SSt #Estimate of effect size (eta2)
  })
  findPOS(samps, estimates, ES, width)$POS
})

# for a single sample
estimates <- sapply(3:n, function(x) {
  pilot.anova <- as.matrix(anova(aov(effect ~ ., data=pilot.data[1:x,])))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  SSb/SSt #Estimate of effect size (eta2)
})
plot(estimates, type="l", ylim=c(0, max(ES, max(estimates))), xlab="Sample Size", ylab=bquote(eta^2))

# True value
pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
SSb <- pilot.anova[1,2]
SSt <- pilot.anova[1,2] + pilot.anova[2,2]
(eta2 <- SSb/SSt) #Estimate of effect size (eta2)
abline(h=ES)
abline(h=ES + c(-1,1) * width, lty=2)
findPOS(samps, estimates, ES, width)$POS


# ------------------------------------------------------------------ v statistic ------------------------------------------------------------------
library(hypergeo)

vstat = function(n,p,Rsq)
{
	"This function takes total sample size, n, the number of parameters, p, and the population
	value of the coefficient of multiple determination, R^2 (Rsq), and outputs the value of 
	the v-measure (Davis-Stober & Dana, 2013)."
	
	if (Rsq<=0) {Rsq = .0001}
  if (Rsq >= 0.25) {Rsq = 0.25}
  r = ((p-1)*(1-Rsq))/((n-p)*Rsq)
  g = min(r,1)
	if (g<.5001 && g>.4999) {g = .5001}
  z = (g - sqrt(g-g^2))/(2*g - 1)
  alpha = acos((1-z)/sqrt(1-2*z*(1-z)))
  v = Re((((2*cos(alpha)*gamma((p+2)/2))/(sqrt(pi)*gamma((p+1)/2)))*(hypergeo(.5,(1-p)/2, 3/2, cos(alpha)^2) - sin(alpha)^(p-1))))
  return(v)
}

find_n <- function(p, v, Rsq) { #finds the n required for a given v statistic v
  ns <- sapply(10:300, function(n) {
    if(vstat(n, p, Rsq) >= v) n
    else NA
  })
  return(ns[which.min(ns)])
}

# need to have at least 3 groups for v statistic to work
n <- 20 # sample size per group

ES = 0.1379 # Large effect size
f2 <- ES/(1-ES)
f <- sqrt(3*f2/2)
muvec <- c(-f, 0, f)


pilot.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= 3*n), 
                          "effect" = rnorm(n = 3*n, mean = rep(muvec, length.out=3*n), sd = 1))
fit <- lm(effect ~., data=pilot.data)
r2 <- summary(fit)$r.squared
pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
SSb <- pilot.anova[1,2]
SSt <- pilot.anova[1,2] + pilot.anova[2,2]
(eta2 <- SSb/SSt) #Estimate of effect size (eta2)
n <- find_n(2, 0.5, r2)
estimate <- r2/(1-r2)

large <- sapply(1:100, function(x){
  pilot.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= 3*n), 
                          "effect" = rnorm(n = 3*n, mean = rep(muvec, length.out=3*n), sd = 1))
  pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  estimate <- SSb/SSt
  
  fit <- lm(effect ~., data=pilot.data)
  r2 <- summary(fit)$r.squared
  n <- find_n(2, 0.5, r2)
  
  c(estimate,n)
})

ES = 0.0588 # medium effect size
f2 <- ES/(1-ES)
f <- sqrt(3*f2/2)
muvec <- c(-f, 0, f)
medium <- sapply(1:100, function(x){
  pilot.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= 3*n), 
                          "effect" = rnorm(n = 3*n, mean = rep(muvec, length.out=3*n), sd = 1))
  pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  estimate <- SSb/SSt
  
  fit <- lm(effect ~., data=pilot.data)
  r2 <- summary(fit)$r.squared
  n <- find_n(2, 0.5, r2)
  
  c(estimate,n)
})

ES = 0.0099 # small effect size
f2 <- ES/(1-ES)
f <- sqrt(3*f2/2)
muvec <- c(-f, 0, f)
small <- sapply(1:100, function(x){
  pilot.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= 3*n), 
                          "effect" = rnorm(n = 3*n, mean = rep(muvec, length.out=3*n), sd = 1))
  pilot.anova <- as.matrix(anova(aov(effect ~ ., data = pilot.data)))
  SSb <- pilot.anova[1,2]
  SSt <- pilot.anova[1,2] + pilot.anova[2,2]
  estimate <- SSb/SSt
  
  fit <- lm(effect ~., data=pilot.data)
  r2 <- summary(fit)$r.squared
  n <- find_n(2, 0.5, r2)
  
  c(estimate,n)
})

large_eff <- sapply(1:100, function(x){
  large[[x]][1]
})
medium_eff <- sapply(1:100, function(x){
  medium[[x]][1]
})
small_eff <- sapply(1:100, function(x){
  small[[x]][1]
})

large_n <- sapply(1:100, function(x){
  large[[x]][2]
})
medium_n <- sapply(1:100, function(x){
  medium[[x]][2]
})
small_n <- sapply(1:100, function(x){
  small[[x]][2]
})

ES = 0.1379 # Large effect size
f2 <- ES/(1-ES)
f <- sqrt(3*f2/2)
muvec <- c(-f, 0, f)
large_p <- sapply(1:100, function(x){
  n = large_n[x]
  if(is.na(n)){ return(NA) }
  study.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= n), 
                          "effect" = rnorm(n = n, mean = rep(muvec, length.out=n), sd = 1))
  study.anova <- as.matrix(anova(aov(effect~.,data=study.data)))
  study.anova[1,5]
})
sum(large_p<0.05, na.rm=TRUE)/(100-sum(is.na(large_p)))


ES = 0.0588 # medium effect size
f2 <- ES/(1-ES)
f <- sqrt(3*f2/2)
muvec <- c(-f, 0, f)
medium_p <- sapply(1:100, function(x){
  n = medium_n[x]
  if(is.na(n)){ return(NA) }
  study.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= n), 
                          "effect" = rnorm(n = n, mean = rep(muvec, length.out=n), sd = 1))
  study.anova <- as.matrix(anova(aov(effect~.,data=study.data)))
  study.anova[1,5]
})
sum(medium_p<0.05, na.rm=TRUE)/(100-sum(is.na(medium_p)))


ES = 0.0099 # small effect size
f2 <- ES/(1-ES)
f <- sqrt(3*f2/2)
muvec <- c(-f, 0, f)
small_p <- sapply(1:100, function(x){
  n = small_n[x]
  if(is.na(n)){ return(NA) }
  study.data  <- data.frame("condition" = rep(as.factor(1:3), length.out= n), 
                          "effect" = rnorm(n = n, mean = rep(muvec, length.out=n), sd = 1))
  study.anova <- as.matrix(anova(aov(effect~.,data=study.data)))
  study.anova[1,5]
})
sum(small_p<0.05, na.rm=TRUE)/(100-sum(is.na(small_p)))
```


```{r}
#Feb 21
library(pwr)
setwd("F:/Chris Ji PC/Documents/Research/Research Paper/papers/when power analyses/conditions")
# simulation with k=2 groups, ES=0.1379, npilot=(10,25,50), alpha=0.05, beta=0.2, R=1000

powerselection= 0.8
ESselection = 0.1379
Kselection = 2


K      <- c(2, 3, 4)        # number of groups in a one-way anova
ES     <- c(.0099,.0588,.1379) # population ES
npilot <- c(10, 25, 50)     # sample size per group in the pilot
alpha  <- 0.05              # nominal level of significance
beta   <- c(0.2, 0.1)       # 1 - power
ESmeasure <- c("eta","epsilon","omega")
R <- 1000 # number of replications per condition
conditions <- expand.grid(ESmeasure,K, npilot, ES, alpha, 1-beta)
colnames(conditions) <- c("ESmeasure", "K", "npilot", "ES", "alpha", "power")

npilot <- c(10, 25, 50)     # sample size per group in the pilot

# Selecting subset of data (cannot load everything in memory at the same time)
nrconditions=162
conditionselection<-c(1:162) #Select conditions
conditions$conditionselect <- conditionselection #Add numbers for 162 conditions to select them below

conditionselection<-subset(conditions, power==powerselection & ES==ESselection & K==Kselection) #Keep only those conditions from 162 we want to plot
conditionselection<-conditionselection$conditionselect
nrconditions=length(conditionselection) #get number of condition we are plotting

conditions<-conditions[conditionselection,] #remove conditions we are not interested in

nMAT <- array(NA, dim=c(nrconditions,R))
ESMAT <- nMAT
pvalueMAT <- nMAT 
for(i in 1:length(conditionselection)){
  cond<-conditionselection[i]
  nMAT[i,] <- readRDS(paste("n_",cond,".rds",sep=""))
  ESMAT[i,] <- readRDS(paste("ES_",cond,".rds",sep=""))
  pvalueMAT[i,] <- readRDS(paste("p_",cond,".rds",sep=""))
}


(nmedian2 <- apply(nMAT,1,median, na.rm=TRUE))  # median sample size needed
(nmean2 <- apply(nMAT,1,mean, na.rm=TRUE))  # mean sample size needed
(biasES <- apply(ESMAT,1,mean, na.rm=TRUE) - conditions$ES)
(meanES <- apply(ESMAT,1,mean, na.rm=TRUE))
(sdES <- apply(ESMAT,1,sd, na.rm=TRUE))
(rmseES <- sqrt(biasES^2 + sdES^2))
(obspower2 <- apply(pvalueMAT,1, function(x) sum(x < .05, na.rm=TRUE)/(R-sum(is.na(x)))))

set.seed(1)
study_data <- sapply(nmedian2, function(x){
    rnorm(2*x, mean = rep(c(-1 * ESselection, ESselection), each=x), sd=1)
})
study_anova <- lapply(1:length(study_data), function(i){
  as.matrix(anova(aov(study_data[[i]] ~ rep(as.factor(1:2),each=nmedian2[i]))))
})

study_data_mean <- sapply(nmean2, function(x){
    rnorm(2*floor(x), mean = rep(c(-1 * ESselection, ESselection), each=x), sd=1)
})
(study_anova_mean <- lapply(1:length(study_data_mean), function(i){
  as.matrix(anova(aov(study_data_mean[[i]] ~ rep(as.factor(1:2),each=nmean2[i]))))
}))



```




```{r}
#Feb 13
library(effsize)
N = 400 # population size
r = 1e+03 # replications
effsize <- seq(0, 1, by=0.1)

##################################### Effect size vs contained in CI ####################################################
CI_effsize_5 <- rep(0, 11) # vector to store mean CI coverage
n = N*0.05 # sample size
for(i in effsize){
  # create population to draw from
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  contained_in_CI <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n) #sample from population
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s) #calculate Cohen's d
    ifelse((i > d$conf.int[1]) & (i < d$conf.int[2]), 1, 0)
  })
  CI_effsize_5[i*10+1] <- mean(contained_in_CI)
}

CI_effsize_10 <- rep(0, 11)
n = N * 0.1
for(i in effsize){
  # create population to draw from
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  contained_in_CI <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n) #sample from population
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s) #calculate Cohen's d
    ifelse((i > d$conf.int[1]) & (i < d$conf.int[2]), 1, 0)
  })
  CI_effsize_10[i*10+1] <- mean(contained_in_CI)
}

plot(effsize, CI_effsize_10, main="Effect size vs CI coverage", col="blue", type="l")
points(effsize, CI_effsize_5, col="red", type="l")
abline(h=0.95)
legend("bottomright", legend=c("5%", "10%"), col=c("red", "blue"), lty=1, title="Sample size")


##################################### Effect size vs contained in SEM ####################################################
SEM_effsize_5 <- rep(0, 11)
n = N*0.05 # sample size
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  contained_in_SEM <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    ifelse((i > d$estimate - d$sd/sqrt(n)) & 
           (i < d$estimate + d$sd/sqrt(n)), 1, 0)
  })
  SEM_effsize_5[i*10+1] <- mean(contained_in_SEM)
}

n = N*0.1 # sample size
SEM_effsize_10 <- rep(0, 11)
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  contained_in_SEM <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    ifelse((i > d$estimate - d$sd/sqrt(n)) & 
           (i < d$estimate + d$sd/sqrt(n)), 1, 0)
  })
  SEM_effsize_10[i*10+1] <- mean(contained_in_SEM)
}
plot(effsize, SEM_effsize_10, main="Effect size vs SEM coverage", col="blue", type="l")
points(effsize, SEM_effsize_5, col="red", type="l")
legend("bottomright", legend=c("5%", "10%"), col=c("red", "blue"), lty=1, title="Sample size")




##################################### Effect size vs CI width ####################################################
CI_width_5 <- rep(0, 11)
n = N*0.05 # sample size
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(d$conf.int[2] - d$conf.int[1])
  })
  CI_width_5[i*10 + 1] <- mean(widths)
}

CI_width_10 <- rep(0, 11)
n = N*0.1
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(d$conf.int[2] - d$conf.int[1])
  })
  CI_width_10[i*10 + 1] <- mean(widths)
}

CI_width_100 <- rep(0, 11)
n = N
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(d$conf.int[2] - d$conf.int[1])
  })
  CI_width_100[i*10 + 1] <- mean(widths)
}

plot(effsize, CI_width_100, ylim=c(0, 2), main="Effect size vs CI width", type="l")
legend("topright", legend=c("5%", "10%", "100%"), col=c("red", "blue", "black"), lty=1, title="Sample size")
points(effsize, CI_width_10, col="blue", type="l")
points(effsize, CI_width_5, col="red", type="l")




##################################### Effect size vs SEM width ####################################################
SEM_width_5 <- rep(0, 11)
n = N*0.05 # sample size
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(2*d$sd/sqrt(n))
  })
  SEM_width_5[i*10 + 1] <- mean(widths)
}

SEM_width_10 <- rep(0, 11)
n = N*0.1
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(2*d$sd/sqrt(n))
  })
  SEM_width_10[i*10 + 1] <- mean(widths)
}

SEM_width_100 <- rep(0, 11)
n = N
for(i in effsize){
  treatment = rnorm(N, mean = i)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, n)
    control_s = sample(control, n)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(2*d$sd/sqrt(n))
  })
  SEM_width_100[i*10 + 1] <- mean(widths)
}

plot(effsize, SEM_width_100, ylim=c(0,0.7), main="Effect size vs SEM width", type="l")
legend("topright", legend=c("5%", "10%", "100%"), col=c("red", "blue", "black"), lty=1, title="Sample size")
points(effsize, SEM_width_10, col="blue", type="l")
points(effsize, SEM_width_5, col="red", type="l")

################################### Sample size vs widths ######################################################
CI_width <- rep(0, 20)
sample_sizes <- seq(0.05, 1, by=0.05)
for(i in sample_sizes){
  treatment = rnorm(N, mean = 0.2)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, i*N)
    control_s = sample(control, i*N)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(d$conf.int[2] - d$conf.int[1])
  })
  CI_width[i*20] <- mean(widths)
}
plot(sample_sizes, CI_width, main="Sample size vs CI width", type="l")

SEM_width <- rep(0, 20)
for(i in sample_sizes){
  treatment = rnorm(N, mean = 0.2)
  control = rnorm(N, mean = 0)
  widths <- sapply(1:r, FUN=function(x){
    treatment_s = sample(treatment, i*N)
    control_s = sample(control, i*N)
    d <- cohen.d(treatment_s, control_s)
    as.numeric(2*d$sd/sqrt(i*N))
  })
  SEM_width[i*20] <- mean(widths)
}
plot(sample_sizes, SEM_width, main="Sample size vs SEM width", type="l")
```






```{r}
#################################### Small effect size ############################################################
N = 800 
n = 20
r = 1000
eff_size <- 0.2 # effect size
treatment = rnorm(N, mean = eff_size)
control = rnorm(N, mean = 0)
(d<- cohen.d(treatment, control))

CI <- sapply(1:r, FUN=function(x){
  treatment_s = sample(treatment, n)
  control_s = sample(control, n)
  ifelse((eff_size > cohen.d(treatment_s, control_s)$conf.int[1]) & (eff_size < cohen.d(treatment_s, control_s)$conf.int[2]), 1, 0)
})

# SEM
SEM <- sapply(1:r, FUN=function(x){
  treatment_s = sample(treatment, n)
  control_s = sample(control, n)
  d <- cohen.d(treatment_s, control_s)
  ifelse((eff_size > d$estimate - d$sd/sqrt(n)) & 
           (eff_size < d$estimate + d$sd/sqrt(n)), 1, 0)
})
```




```{r}
library(simstudy)
library(parallel)
library(nlme)
library(data.table)

d1 <- defData(varname = "x1", formula = 0, variance = 1, dist = "normal")


d2 <- defDataAdd(varname = "y", formula = "5 + 10*grp", dist = "normal", variance=1)
dd <- genData(5, d1)
dd <- trtAssign(dd, nTrt = 2, grpName = "grp")
(dd <- addColumns(d2, dd))
```